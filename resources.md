---
title: Hackathon resources
menu_title: Resources
menu_icon: journal-code
---

<ul class="grid">
<li class="resource-block" markdown="1">

## LLM Tutorials and tools 

#### [Langchain demo](https://www.youtube.com/watch?v=zaYTXQFR0_s) - an overview of the capabilities of LangChain.

{% include youtube.html video="zaYTXQFR0_s" title="" %}


#### [Huggingface walkthrough](https://www.youtube.com/watch?v=QEaBAZQCtwE) -- very quick overview of the most important functionalities of HuggingFace

{% include youtube.html video="QEaBAZQCtwE" title="" %}


</li>



<li class="resource-block" markdown="1">
## Project inspirations 

#### [Paper QA](https://huggingface.co/spaces/whitead/paper-qa) -- doing question and answering from PDFs or text files (e.g. papers)

<blockquote class="twitter-tweet"><p lang="en" dir="ltr">I packed-up a full-text paper scraper, vector database, and LLM into a CLI to answer questions from only highly-cited peer-reviewed papers. Feels unreal to be able instantly get answers by an LLM &quot;reading&quot; dozens of papers. 1/2 <a href="https://t.co/a6PWxWyuc1">pic.twitter.com/a6PWxWyuc1</a></p>&mdash; Andrew White ‚è£üß™ (@andrewwhite01) <a href="https://twitter.com/andrewwhite01/status/1629346569756483584?ref_src=twsrc%5Etfw">February 25, 2023</a></blockquote> <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>


#### [Few-shot predictions for chemistry using GPT-4](https://twitter.com/kmjablonka/status/1635794978936066049?s=20) --  A very interesting recent finding is that LLMs can give surprisingly good predictions on chemistry examples *without any training*, only with a few examples in the prompt. 

<blockquote class="twitter-tweet"><p lang="en" dir="ltr">One of my favorite examples in our preprint (<a href="https://t.co/ojby0bSaoj">https://t.co/ojby0bSaoj</a>) with <a href="https://twitter.com/SmitBerend?ref_src=twsrc%5Etfw">@SmitBerend</a> and <a href="https://twitter.com/pschwllr?ref_src=twsrc%5Etfw">@pschwllr</a> and @aortegaguerrerowas about photoswitches curated by <a href="https://twitter.com/Ryan__Rhys?ref_src=twsrc%5Etfw">@Ryan__Rhys</a>.<br><br>I now asked <a href="https://twitter.com/hashtag/GPT?src=hash&amp;ref_src=twsrc%5Etfw">#GPT</a>-4 a few questions about it. <a href="https://t.co/O7O1078mib">pic.twitter.com/O7O1078mib</a></p>&mdash; Kevin Jablonka (@kmjablonka) <a href="https://twitter.com/kmjablonka/status/1635794978936066049?ref_src=twsrc%5Etfw">March 15, 2023</a></blockquote> <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>


#### [MARVIS](https://github.com/whitead/marvis) --- Text/Voice-control for VMD.

<blockquote class="twitter-tweet"><p lang="en" dir="ltr">Here&#39;s a text demo of Marvis from <a href="https://twitter.com/glenhocky?ref_src=twsrc%5Etfw">@glenhocky</a> and me. Info: <a href="https://t.co/DQLKYpwZsX">https://t.co/DQLKYpwZsX</a> Code: <a href="https://t.co/LjzwjS4zR9">https://t.co/LjzwjS4zR9</a> <a href="https://t.co/wn3PNBrpmb">pic.twitter.com/wn3PNBrpmb</a></p>&mdash; Andrew White ‚è£üß™ (@andrewwhite01) <a href="https://twitter.com/andrewwhite01/status/1392517379326894080?ref_src=twsrc%5Etfw">May 12, 2021</a></blockquote> <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

</li>

<li class="resource-block" markdown="1">
## Guidelines

### [Submission](_/../resources/submission.md) - The hackathon's workflow for submissions

</li>

</ul>